{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "seaborn.set(style='whitegrid'); seaborn.set_context('talk')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = iris_data.data.shape\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_plot = plt.scatter(iris_data.data[:,0], iris_data.data[:,1], alpha=0.5, \n",
    "                           c=iris_data.target) \n",
    "plt.colorbar(ticks=([0, 1, 2]))\n",
    "plt.title('Sepal Sample')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_plot_2 = plt.scatter(iris_data.data[:,2], iris_data.data[:,3], alpha=0.5, \n",
    "                           c=iris_data.target)\n",
    "plt.colorbar(ticks=([0, 1, 2]))\n",
    "plt.title('Petal Sample')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "def separate_data():\n",
    "    A = iris_dataset[0:40]\n",
    "    tA = iris_dataset[40:50]\n",
    "    B = iris_dataset[50:90]\n",
    "    tB = iris_dataset[90:100]\n",
    "    C = iris_dataset[100:140]\n",
    "    tC = iris_dataset[140:150]\n",
    "    train = np.concatenate((A,B,C))\n",
    "    test =  np.concatenate((tA,tB,tC))\n",
    "    return train,test\n",
    "\n",
    "train_porcent = 80 # Porcent Training \n",
    "test_porcent = 20 # Porcent Test\n",
    "iris_dataset = np.column_stack((iris_data.data,iris_data.target.T)) #Join X and Y\n",
    "iris_dataset = list(iris_dataset)\n",
    "random.shuffle(iris_dataset)\n",
    "\n",
    "Filetrain, Filetest = separate_data()\n",
    "\n",
    "train_X = np.array([i[:4] for i in Filetrain])\n",
    "train_y = np.array([i[4] for i in Filetrain])\n",
    "test_X = np.array([i[:4] for i in Filetest])\n",
    "test_y = np.array([i[4] for i in Filetest])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting our training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(train_X[:,0],train_X[:,1],c=train_y,cmap=cm.viridis)\n",
    "plt.xlabel(iris_data.feature_names[0])\n",
    "plt.ylabel(iris_data.feature_names[1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(train_X[:,2],train_X[:,3],c=train_y,cmap=cm.viridis)\n",
    "plt.xlabel(iris_data.feature_names[2])\n",
    "plt.ylabel(iris_data.feature_names[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot our test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(test_X[:,0],test_X[:,1],c=test_y,cmap=cm.viridis)\n",
    "plt.xlabel(iris_data.feature_names[0])\n",
    "plt.ylabel(iris_data.feature_names[1]) \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_X[:,2],test_X[:,3],c=test_y,cmap=cm.viridis)\n",
    "plt.xlabel(iris_data.feature_names[2])\n",
    "plt.ylabel(iris_data.feature_names[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0 \n",
    "ativation = {(lambda x: 1/(1 + np.exp(-x)))}\n",
    "deriv = {(lambda x: x*(1-x))}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Implementation the Multilayer Perceptron in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "import random\n",
    "\n",
    "class MultiLayerPerceptron(BaseEstimator, ClassifierMixin): \n",
    "    def __init__(self, params=None):     \n",
    "        if (params == None):\n",
    "            self.inputLayer = 4                        # Input Layer\n",
    "            self.hiddenLayer = 5                       # Hidden Layer\n",
    "            self.outputLayer = 3                       # Outpuy Layer\n",
    "            self.learningRate = 0.005                  # Learning rate\n",
    "            self.max_epochs = 600                      # Epochs\n",
    "            self.iasHiddenValue = -1                   # Bias HiddenLayer\n",
    "            self.BiasOutputValue = -1                  # Bias OutputLayer\n",
    "            self.activation = self.ativacao['sigmoid'] # Activation function\n",
    "            self.deriv = self.derivada['sigmoid']\n",
    "        else:\n",
    "            self.inputLayer = params['InputLayer']\n",
    "            self.hiddenLayer = params['HiddenLayer']\n",
    "            self.OutputLayer = params['OutputLayer']\n",
    "            self.learningRate = params['LearningRate']\n",
    "            self.max_epochs = params['Epocas']\n",
    "            self.BiasHiddenValue = params['BiasHiddenValue']\n",
    "            self.BiasOutputValue = params['BiasOutputValue']\n",
    "            self.activation = self.ativacao[params['ActivationFunction']]\n",
    "            self.deriv = self.derivada[params['ActivationFunction']]\n",
    "        \n",
    "        'Starting Bias and Weights'\n",
    "        self.WEIGHT_hidden = self.starting_weights(self.hiddenLayer, self.inputLayer)\n",
    "        self.WEIGHT_output = self.starting_weights(self.OutputLayer, self.hiddenLayer)\n",
    "        self.BIAS_hidden = np.array([self.BiasHiddenValue for i in range(self.hiddenLayer)])\n",
    "        self.BIAS_output = np.array([self.BiasOutputValue for i in range(self.OutputLayer)])\n",
    "        self.classes_number = 3 \n",
    "        \n",
    "    pass\n",
    "    \n",
    "    def starting_weights(self, x, y):\n",
    "        return [[2  * random.random() - 1 for i in range(x)] for j in range(y)]\n",
    "\n",
    "    ativacao = {\n",
    "         'sigmoid': (lambda x: 1/(1 + np.exp(-x))),\n",
    "            \n",
    "               }\n",
    "    derivada = {\n",
    "         'sigmoid': (lambda x: x*(1-x)),\n",
    "            \n",
    "               }\n",
    " \n",
    "    def Backpropagation_Algorithm(self, x):\n",
    "        DELTA_output = []\n",
    "        'Stage 1 - Error: OutputLayer'\n",
    "        ERROR_output = self.output - self.OUTPUT_L2\n",
    "        DELTA_output = ((-1)*(ERROR_output) * self.deriv(self.OUTPUT_L2))\n",
    "        \n",
    "        arrayStore = []\n",
    "        'Stage 2 - Update weights OutputLayer and HiddenLayer'\n",
    "        for i in range(self.hiddenLayer):\n",
    "            for j in range(self.OutputLayer):\n",
    "                self.WEIGHT_output[i][j] -= (self.learningRate * (DELTA_output[j] * self.OUTPUT_L1[i]))\n",
    "                self.BIAS_output[j] -= (self.learningRate * DELTA_output[j])\n",
    "      \n",
    "        'Stage 3 - Error: HiddenLayer'\n",
    "        delta_hidden = np.matmul(self.WEIGHT_output, DELTA_output)* self.deriv(self.OUTPUT_L1)\n",
    " \n",
    "        'Stage 4 - Update weights HiddenLayer and InputLayer(x)'\n",
    "        for i in range(self.OutputLayer):\n",
    "            for j in range(self.hiddenLayer):\n",
    "                self.WEIGHT_hidden[i][j] -= (self.learningRate * (delta_hidden[j] * x[i]))\n",
    "                self.BIAS_hidden[j] -= (self.learningRate * delta_hidden[j])\n",
    "                \n",
    "    def show_err_graphic(self,v_erro,v_epoca):\n",
    "        plt.figure(figsize=(9,4))\n",
    "        plt.plot(v_epoca, v_erro, \"m-\",color=\"b\", marker=11)\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Squared error (MSE) \");\n",
    "        plt.title(\"Error Minimization\")\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        'Returns the predictions for every element of X'\n",
    "        my_predictions = []\n",
    "        'Forward Propagation'\n",
    "        forward = np.matmul(X,self.WEIGHT_hidden) + self.BIAS_hidden\n",
    "        forward = np.matmul(forward, self.WEIGHT_output) + self.BIAS_output\n",
    "                                 \n",
    "        for i in forward:\n",
    "            my_predictions.append(max(enumerate(i), key=lambda x:x[1])[0])\n",
    "            \n",
    "        array_score = []\n",
    "        for i in range(len(my_predictions)):\n",
    "            if my_predictions[i] == 0: \n",
    "                array_score.append([i, 'Iris-setosa', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 1:\n",
    "                 array_score.append([i, 'Iris-versicolour', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 2:\n",
    "                 array_score.append([i, 'Iris-virginica', my_predictions[i], y[i]])\n",
    "                    \n",
    "        dataframe = pd.DataFrame(array_score, columns=['_id', 'class', 'output', 'hoped_output'])\n",
    "        return my_predictions, dataframe\n",
    "\n",
    "    def fit(self, X, y):  \n",
    "        count_epoch = 1\n",
    "        total_error = 0\n",
    "        n = len(X); \n",
    "        epoch_array = []\n",
    "        error_array = []\n",
    "        W0 = []\n",
    "        W1 = []\n",
    "        while(count_epoch <= self.max_epochs):\n",
    "            for idx,inputs in enumerate(X): \n",
    "                self.output = np.zeros(self.classes_number)\n",
    "                'Stage 1 - (Forward Propagation)'\n",
    "                self.OUTPUT_L1 = self.activation((np.dot(inputs, self.WEIGHT_hidden) + self.BIAS_hidden.T))\n",
    "                self.OUTPUT_L2 = self.activation((np.dot(self.OUTPUT_L1, self.WEIGHT_output) + self.BIAS_output.T))\n",
    "                'Stage 2 - One-Hot-Encoding'\n",
    "                if(y[idx] == 0): \n",
    "                    self.output = np.array([1,0,0]) #Class1 {1,0,0}\n",
    "                elif(y[idx] == 1):\n",
    "                    self.output = np.array([0,1,0]) #Class2 {0,1,0}\n",
    "                elif(y[idx] == 2):\n",
    "                    self.output = np.array([0,0,1]) #Class3 {0,0,1}\n",
    "                \n",
    "                square_error = 0\n",
    "                for i in range(self.OutputLayer):\n",
    "                    erro = (self.output[i] - self.OUTPUT_L2[i])**2\n",
    "                    square_error = (square_error + (0.05 * erro))\n",
    "                    total_error = total_error + square_error\n",
    "         \n",
    "                'Backpropagation : Update Weights'\n",
    "                self.Backpropagation_Algorithm(inputs)\n",
    "                \n",
    "            total_error = (total_error / n)\n",
    "            if((count_epoch % 50 == 0)or(count_epoch == 1)):\n",
    "                print(\"Epoch \", count_epoch, \"- Total Error: \",total_error)\n",
    "                error_array.append(total_error)\n",
    "                epoch_array.append(count_epoch)\n",
    "                \n",
    "            W0.append(self.WEIGHT_hidden)\n",
    "            W1.append(self.WEIGHT_output)\n",
    "             \n",
    "                \n",
    "            count_epoch += 1\n",
    "        self.show_err_graphic(error_array,epoch_array)\n",
    "        \n",
    "        plt.plot(W0[0])\n",
    "        plt.title('Weight Hidden update during training')\n",
    "        plt.legend(['neuron1', 'neuron2', 'neuron3', 'neuron4', 'neuron5'])\n",
    "        plt.ylabel('Value Weight')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(W1[0])\n",
    "        plt.title('Weight Output update during training')\n",
    "        plt.legend(['neuron1', 'neuron2', 'neuron3'])\n",
    "        plt.ylabel('Value Weight')\n",
    "        plt.show()\n",
    "\n",
    "        return self"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test():\n",
    "    ep1 = [0,100,200,300,400,500,600,700,800,900,1000,1500,2000]\n",
    "    h_5 = [0,60,70,70,83.3,93.3,96.7,86.7,86.7,76.7,73.3,66.7,66.7]\n",
    "    h_4 = [0,40,70,63.3,66.7,70,70,70,70,66.7,66.7,43.3,33.3]\n",
    "    h_3 = [0,46.7,76.7,80,76.7,76.7,76.6,73.3,73.3,73.3,73.3,76.7,76.7]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    l1, = plt.plot(ep1, h_3, \"--\",color='b',label=\"node-3\", marker=11)\n",
    "    l2, = plt.plot(ep1, h_4, \"--\",color='g',label=\"node-4\", marker=8)\n",
    "    l3, = plt.plot(ep1, h_5, \"--\",color='r',label=\"node-5\", marker=5)\n",
    "    plt.legend(handles=[l1,l2,l3], loc=1)\n",
    "    plt.xlabel(\"number of Epochs\")\n",
    "    plt.ylabel(\"% Hits\")\n",
    "    plt.title(\"Number of Hidden Layers - Performance\")\n",
    "    \n",
    "    ep2 = [0,100,200,300,400,500,600,700]\n",
    "    tanh = [0.18,0.027,0.025,0.022,0.0068,0.0060,0.0057,0.00561]\n",
    "    sigm = [0.185,0.0897,0.060,0.0396,0.0343,0.0314,0.0296,0.0281]\n",
    "    Relu = [0.185,0.05141,0.05130,0.05127,0.05124,0.05123,0.05122,0.05121]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    l1 , = plt.plot(ep2, tanh, \"--\",color='b',label=\"Hyperbolic Tangent\",marker=11)\n",
    "    l2 , = plt.plot(ep2, sigm, \"--\",color='g',label=\"Sigmoide\", marker=8)\n",
    "    l3 , = plt.plot(ep2, Relu, \"--\",color='r',label=\"ReLu\", marker=5)\n",
    "    plt.legend(handles=[l1,l2,l3], loc=1)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Activation Functions - Performance\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    names = [\"Hyperbolic Tangent\",\"Sigmoide\",\"ReLU\"]\n",
    "    x1 = [2.0,4.0,6.0]\n",
    "    plt.bar(x1[0], 53.4,0.4,color='b')\n",
    "    plt.bar(x1[1], 96.7,0.4,color='g')\n",
    "    plt.bar(x1[2], 33.2,0.4,color='r')\n",
    "    plt.xticks(x1,names)\n",
    "    plt.ylabel('% Hits')\n",
    "    plt.title('Hits - Activation Functions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'InputLayer':4, 'HiddenLayer':5, 'OutputLayer':3,\n",
    "              'Epocas':700, 'LearningRate':0.005,'BiasHiddenValue':-1, \n",
    "              'BiasOutputValue':-1, 'ActivationFunction':'sigmoid'}\n",
    "\n",
    "Perceptron = MultiLayerPerceptron(dictionary)\n",
    "Perceptron.fit(train_X,train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev, dataframe = Perceptron.predict(test_X, test_y)\n",
    "hits = n_set = n_vers = n_virg = 0\n",
    "score_set = score_vers = score_virg = 0\n",
    "for j in range(len(test_y)):\n",
    "    if(test_y[j] == 0): n_set += 1\n",
    "    elif(test_y[j] == 1): n_vers += 1\n",
    "    elif(test_y[j] == 2): n_virg += 1\n",
    "        \n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] == prev[i]: \n",
    "        hits += 1\n",
    "    if test_y[i] == prev[i] and test_y[i] == 0:\n",
    "        score_set += 1\n",
    "    elif test_y[i] == prev[i] and test_y[i] == 1:\n",
    "        score_vers += 1\n",
    "    elif test_y[i] == prev[i] and test_y[i] == 2:\n",
    "        score_virg += 1    \n",
    "         \n",
    "hits = (hits / len(test_y)) * 100\n",
    "faults = 100 - hits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and precision the Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_hits = []\n",
    "print(\"Porcents :\",\"%.2f\"%(hits),\"% hits\",\"and\",\"%.2f\"%(faults),\"% faults\")\n",
    "print(\"Total samples of test\",n_samples)\n",
    "print(\"*Iris-Setosa:\",n_set,\"samples\")\n",
    "print(\"*Iris-Versicolour:\",n_vers,\"samples\")\n",
    "print(\"*Iris-Virginica:\",n_virg,\"samples\")\n",
    "\n",
    "graph_hits.append(hits)\n",
    "graph_hits.append(faults)\n",
    "labels = 'Hits', 'Faults';\n",
    "sizes = [96.5, 3.3]\n",
    "explode = (0, 0.14)\n",
    "\n",
    "fig1, ax1 = plt.subplots();\n",
    "ax1.pie(graph_hits, explode=explode,colors=['green','red'],labels=labels, autopct='%1.1f%%',\n",
    "shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Score for each one of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_set = (score_set/n_set)*100\n",
    "acc_vers = (score_vers/n_vers)*100\n",
    "acc_virg = (score_virg/n_virg)*100\n",
    "print(\"- Acurracy Iris-Setosa:\",\"%.2f\"%acc_set, \"%\")\n",
    "print(\"- Acurracy Iris-Versicolour:\",\"%.2f\"%acc_vers, \"%\")\n",
    "print(\"- Acurracy Iris-Virginica:\",\"%.2f\"%acc_virg, \"%\")\n",
    "names = [\"Setosa\",\"Versicolour\",\"Virginica\"]\n",
    "x1 = [2.0,4.0,6.0]\n",
    "fig, ax = plt.subplots()\n",
    "r1 = plt.bar(x1[0], acc_set,color='orange',label='Iris-Setosa')\n",
    "r2 = plt.bar(x1[1], acc_vers,color='green',label='Iris-Versicolour')\n",
    "r3 = plt.bar(x1[2], acc_virg,color='purple',label='Iris-Virginica')\n",
    "plt.ylabel('Scores %')\n",
    "plt.xticks(x1, names);plt.title('Scores by iris flowers - Multilayer Perceptron')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
